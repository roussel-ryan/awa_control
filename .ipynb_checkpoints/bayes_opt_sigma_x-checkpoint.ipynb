{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377b9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:awa_interface:Starting controller_interface\n",
      "INFO:awa_interface:Connecting to AWAPGCamera application\n",
      "INFO:awa_interface:Done\n",
      "INFO:xopt.bayesian.optimize:started running optimization with generator: <xopt.bayesian.generators.generator.BayesianGenerator object at 0x00000167BD87B640>\n",
      "INFO:xopt.bayesian.optimize:submitting initial candidates at time 2021-10-19T14:58:36-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:awa_interface:camera client not ready for data\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:starting optimization loop\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:01:17-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:01:23-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:01:34-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:01:43-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:01:51-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:04-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:13-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:23-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:34-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:44-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:02:55-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:02-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:12-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:21-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:28-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:38-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:48-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:03:56-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:05-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:13-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:19-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:27-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:34-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:43-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:50-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:04:58-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:10-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:17-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:28-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:36-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:47-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:05:54-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:00-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:13-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:22-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:32-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:39-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:06:50-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:00-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:13-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:26-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:37-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:47-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:07:57-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:10-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:20-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "e:\\AWASoftware\\xopt\\xopt\\awa_control\\observations\\yag_screen.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  outputs[ele] = np.array(outputs[ele])\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:26-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "e:\\AWASoftware\\xopt\\xopt\\awa_control\\observations\\yag_screen.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  outputs[ele] = np.array(outputs[ele])\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:33-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "e:\\AWASoftware\\xopt\\xopt\\awa_control\\observations\\yag_screen.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  outputs[ele] = np.array(outputs[ele])\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:39-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "INFO:xopt.bayesian.optimize:submitting candidates at time 2021-10-19T15:08:47-05:00\n",
      "INFO:awa_interface:taking n samples 5\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n",
      "WARNING:observations.image_processing:ROI is clipping the beam envelope\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import numpy as np\n",
    "import time\n",
    "import awa_interface\n",
    "from observations.yag_screen import YAGScreen\n",
    "from xopt.bayesian.algorithms import bayesian_optimize\n",
    "\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound\n",
    "\n",
    "def acq(model):\n",
    "    return UpperConfidenceBound(model, beta=2.0)\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, interface):\n",
    "        self.interface = interface\n",
    "\n",
    "    def evaluate_emittance(self, inputs):\n",
    "        self.interface.set_parameters(inputs)\n",
    "\n",
    "        time.sleep(1.0)\n",
    "\n",
    "        observation = YAGScreen(self.interface,\n",
    "                                n_samples=5,\n",
    "                                average_measurements=True)\n",
    "\n",
    "        results = observation.measure_screen()\n",
    "        logging.debug('done analyzing images')\n",
    "        \n",
    "        #remove a bunch of excess info\n",
    "        pop_args = ['ellipses', 'processed_images', 'raw_images']\n",
    "        for ele in pop_args:\n",
    "            results.pop(ele)\n",
    "        results['total_rms'] = np.sqrt(results['rms_x']**2 + results['rms_y']**2)\n",
    "        return results\n",
    "\n",
    "\n",
    "VOCS = {\n",
    "    'name': 'AWA_Opt',\n",
    "\n",
    "    'variables': {\n",
    "        #'Drive:Ctrl:DS1': [6.05, 9.07],  # Focusing Solenoid\n",
    "        #'Drive:Ctrl:DS3': [0.0, 2.5],  # Matching Solenoid\n",
    "        #'SMCtrl:AWA:abs03': [-640, 640],  # Linac Phase\n",
    "        'AWA:Bira3Ctrl:Ch03': [-0.0, 5.0],  # DQ4\n",
    "        'AWA:Bira3Ctrl:Ch04': [-0.0, 5.0],  # DQ5\n",
    "        'AWA:Bira3Ctrl:Ch05': [-5.0, 5.0],  # DQ6\n",
    "\n",
    "    },\n",
    "\n",
    "    'objectives': {\n",
    "        'total_rms': 'MINIMIZE',\n",
    "    },\n",
    "\n",
    "    'constraints': {\n",
    "        #'rms_x': ['LESS_THAN', 150],\n",
    "        #'rms_y': ['LESS_THAN', 150],\n",
    "        #'centroid_offset': ['LESS_THAN', 500],\n",
    "\n",
    "    },\n",
    "    'constants': {'AWA:Bira3Ctrl:Ch06': 5.0}\n",
    "\n",
    "}\n",
    "\n",
    "awa_interface = awa_interface.AWAInterface(use_frame_grabber=False, testing=False)\n",
    "evaluator = Evaluator(awa_interface)\n",
    "opt_results = bayesian_optimize(VOCS,\n",
    "                                   evaluator.evaluate_emittance,\n",
    "                                   n_initial_samples=5,\n",
    "                                   n_steps=50,\n",
    "                               generator_options= {'acquisition_function':acq})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e95da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variables': tensor([[-2.2032, -3.7300,  3.9539],\n",
      "        [-3.9761,  2.7900,  1.1156],\n",
      "        [-3.0951, -1.1419,  3.5248],\n",
      "        [ 3.6750,  1.6897,  4.9750],\n",
      "        [-2.2488,  3.9957, -2.6907],\n",
      "        [-4.9792, -0.4386,  4.8316],\n",
      "        [-2.9816, -0.8225,  1.3922],\n",
      "        [-1.6809, -0.6715,  4.1012],\n",
      "        [-4.0850, -1.6629,  2.6394],\n",
      "        [-5.0000, -2.0050,  1.2500],\n",
      "        [-3.3268, -0.4871,  3.0450],\n",
      "        [-4.2031, -1.3160,  3.1536],\n",
      "        [-5.0000, -1.8478,  3.1697],\n",
      "        [-3.9648, -1.9199,  5.0000],\n",
      "        [-4.0574, -0.7891,  2.2431],\n",
      "        [-3.8055, -2.1685,  2.8271],\n",
      "        [-3.8490, -1.4162,  3.0262],\n",
      "        [-4.2453, -2.6388,  2.3308],\n",
      "        [-4.2515, -2.6424,  3.5699],\n",
      "        [-4.1723, -2.8858,  0.9022],\n",
      "        [-4.2496, -2.0008,  1.7519],\n",
      "        [-3.8841, -3.9965,  1.8025],\n",
      "        [-3.8502, -2.5021,  1.0120],\n",
      "        [-4.1381, -3.2677,  3.0080],\n",
      "        [-4.0665, -1.1011,  3.7873],\n",
      "        [-3.8797, -2.3527,  2.0868],\n",
      "        [-4.1349, -2.4174,  2.2873],\n",
      "        [-2.2203,  2.3641,  2.2695],\n",
      "        [-2.7391,  1.6044,  5.0000],\n",
      "        [-1.9602,  3.5827,  5.0000],\n",
      "        [-1.5669,  2.9395,  0.5864],\n",
      "        [-3.4225, -0.1325,  5.0000],\n",
      "        [-2.6792,  1.7836,  2.1689],\n",
      "        [-3.8132, -2.6709,  4.3677],\n",
      "        [-2.5778,  4.1381,  3.2217],\n",
      "        [-2.9717,  1.4699,  5.0000],\n",
      "        [-2.4623,  1.6979,  5.0000],\n",
      "        [-2.6070,  1.9181,  0.2747],\n",
      "        [-3.9699, -3.0457, -0.2749],\n",
      "        [-2.9616,  1.6758,  2.6633],\n",
      "        [-4.1138, -2.2620,  3.6731],\n",
      "        [-2.4262,  4.4027,  1.2219],\n",
      "        [-2.3081,  5.0000,  1.3645],\n",
      "        [-2.6052,  5.0000,  0.6208],\n",
      "        [-2.0310,  5.0000,  2.1410],\n",
      "        [-2.2521,  2.9639,  1.3339],\n",
      "        [-2.4120,  5.0000,  5.0000],\n",
      "        [-2.3300,  3.4777,  2.8650],\n",
      "        [-2.0834,  5.0000,  1.9283],\n",
      "        [-2.7913,  3.4872,  5.0000],\n",
      "        [-3.1327,  0.5864,  5.0000],\n",
      "        [-3.1606,  0.6473,  5.0000],\n",
      "        [-3.1860,  0.8935,  5.0000],\n",
      "        [-3.2122,  1.2663,  5.0000],\n",
      "        [-3.1162,  0.0985,  5.0000]], dtype=torch.float64), 'objectives': tensor([[317.1463],\n",
      "        [292.4853],\n",
      "        [154.6024],\n",
      "        [352.4660],\n",
      "        [189.1569],\n",
      "        [237.6007],\n",
      "        [192.2500],\n",
      "        [200.1647],\n",
      "        [ 75.3349],\n",
      "        [344.1040],\n",
      "        [170.6844],\n",
      "        [ 73.2252],\n",
      "        [300.7498],\n",
      "        [180.6443],\n",
      "        [172.4793],\n",
      "        [167.1098],\n",
      "        [197.3719],\n",
      "        [ 31.6696],\n",
      "        [193.5383],\n",
      "        [130.6629],\n",
      "        [216.9086],\n",
      "        [171.7489],\n",
      "        [190.2456],\n",
      "        [197.3883],\n",
      "        [215.4126],\n",
      "        [189.2527],\n",
      "        [205.1738],\n",
      "        [174.5267],\n",
      "        [172.2416],\n",
      "        [189.0271],\n",
      "        [208.3424],\n",
      "        [169.9572],\n",
      "        [169.6843],\n",
      "        [171.6409],\n",
      "        [176.2019],\n",
      "        [165.1877],\n",
      "        [187.5405],\n",
      "        [169.4541],\n",
      "        [188.3208],\n",
      "        [169.3311],\n",
      "        [203.0131],\n",
      "        [151.7149],\n",
      "        [141.5672],\n",
      "        [217.8507],\n",
      "        [171.3348],\n",
      "        [168.0818],\n",
      "        [170.3943],\n",
      "        [164.0334],\n",
      "        [171.9533],\n",
      "        [170.8643],\n",
      "        [ 69.8894],\n",
      "        [ 59.5382],\n",
      "        [ 75.9710],\n",
      "        [158.5854],\n",
      "        [163.1759]], dtype=torch.float64), 'corrected_objectives': tensor([[-317.1463],\n",
      "        [-292.4853],\n",
      "        [-154.6024],\n",
      "        [-352.4660],\n",
      "        [-189.1569],\n",
      "        [-237.6007],\n",
      "        [-192.2500],\n",
      "        [-200.1647],\n",
      "        [ -75.3349],\n",
      "        [-344.1040],\n",
      "        [-170.6844],\n",
      "        [ -73.2252],\n",
      "        [-300.7498],\n",
      "        [-180.6443],\n",
      "        [-172.4793],\n",
      "        [-167.1098],\n",
      "        [-197.3719],\n",
      "        [ -31.6696],\n",
      "        [-193.5383],\n",
      "        [-130.6629],\n",
      "        [-216.9086],\n",
      "        [-171.7489],\n",
      "        [-190.2456],\n",
      "        [-197.3883],\n",
      "        [-215.4126],\n",
      "        [-189.2527],\n",
      "        [-205.1738],\n",
      "        [-174.5267],\n",
      "        [-172.2416],\n",
      "        [-189.0271],\n",
      "        [-208.3424],\n",
      "        [-169.9572],\n",
      "        [-169.6843],\n",
      "        [-171.6409],\n",
      "        [-176.2019],\n",
      "        [-165.1877],\n",
      "        [-187.5405],\n",
      "        [-169.4541],\n",
      "        [-188.3208],\n",
      "        [-169.3311],\n",
      "        [-203.0131],\n",
      "        [-151.7149],\n",
      "        [-141.5672],\n",
      "        [-217.8507],\n",
      "        [-171.3348],\n",
      "        [-168.0818],\n",
      "        [-170.3943],\n",
      "        [-164.0334],\n",
      "        [-171.9533],\n",
      "        [-170.8643],\n",
      "        [ -69.8894],\n",
      "        [ -59.5382],\n",
      "        [ -75.9710],\n",
      "        [-158.5854],\n",
      "        [-163.1759]], dtype=torch.float64), 'constraint_status': tensor([], size=(55, 0), dtype=torch.bool), 'feasibility': tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]]), 'model': SingleTaskGP(\n",
      "  (likelihood): GaussianLikelihood(\n",
      "    (noise_covar): HomoskedasticNoise(\n",
      "      (noise_prior): GammaPrior()\n",
      "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
      "    )\n",
      "  )\n",
      "  (mean_module): ConstantMean()\n",
      "  (covar_module): ScaleKernel(\n",
      "    (base_kernel): MaternKernel(\n",
      "      (lengthscale_prior): GammaPrior()\n",
      "      (raw_lengthscale_constraint): Positive()\n",
      "      (distance_module): Distance()\n",
      "    )\n",
      "    (outputscale_prior): GammaPrior()\n",
      "    (raw_outputscale_constraint): Positive()\n",
      "  )\n",
      "  (outcome_transform): Standardize()\n",
      "  (input_transform): Normalize()\n",
      "), 'constraints': tensor([], size=(55, 0), dtype=torch.float64), 'corrected_constraints': tensor([], size=(55, 0), dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "print(opt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0a2f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AWA:Bira3Ctrl:Ch03': tensor(-3.1860, dtype=torch.float64), 'AWA:Bira3Ctrl:Ch04': tensor(0.8935, dtype=torch.float64), 'AWA:Bira3Ctrl:Ch05': tensor(5., dtype=torch.float64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:awa_interface:taking n samples 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.456043080113645\n",
      "65.08569758035762\n",
      "155.83658718487808\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X = opt_results['variables'][-3]\n",
    "X_in = dict(zip(VOCS['variables'], X))\n",
    "print(X_in)\n",
    "res = evaluator.evaluate_emittance(X_in)\n",
    "print(res['rms_x'])\n",
    "print(res['rms_y'])\n",
    "print(res['centroid_offset'])\n",
    "print(res['n_blobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85710b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rms_x', 'rms_y', 'n_blobs', 'image_check', 'centroid_offset', 'total_intensity', 'FWHMX', 'FWHMY', 'FWHML', 'CX', 'CY', 'charge', 'ROI', 'total_rms'])\n",
      "[[-4.51303499e-09  5.77353517e-10 -2.06876474e-10  3.30821121e-10]\n",
      " [-4.51303499e-09 -6.63809294e-11 -1.16000028e-10 -2.03085848e-10]\n",
      " [-3.64393593e-09 -6.63809294e-11 -1.16000028e-10 -2.03085848e-10]\n",
      " [-3.95105185e-09 -1.52677202e-09  1.52582981e-10 -1.18874228e-09]\n",
      " [-4.66734403e-09 -2.85325727e-09 -8.29237481e-10 -1.18874228e-09]]\n"
     ]
    }
   ],
   "source": [
    "print(res.keys())\n",
    "print(res['charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b307d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopt",
   "language": "python",
   "name": "xopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
